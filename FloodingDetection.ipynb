{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import itertools\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "from keras import backend\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.applications import imagenet_utils\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.mobilenetv2 import decode_predictions, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "labels = ['1', '0']\n",
    "train_path = '.../Data/Dataset/foder_origin/train'\n",
    "valid_path = '.../Data/Dataset/foder_origin/validation'\n",
    "\n",
    "# Creating batches of data\n",
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input).flow_from_directory(\n",
    "    directory=train_path, target_size=(224,224), batch_size=10)\n",
    "valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input).flow_from_directory(\n",
    "    directory=valid_path, target_size=(224,224), batch_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained mobilenet model\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "mobile = MobileNetV2(weights='imagenet', include_top=False)\n",
    "mobile.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only training the last 12 layers of the mobilenet during finetuning as we want\n",
    "# Keep all of the previously learned weights\n",
    "x = mobile.layers[-12].output\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add pooling, dropout layer\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n",
    "output = Dense(units=2, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hoàn thiện model với output tùy chỉnh\n",
    "model = Model(inputs=mobile.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the weights the same except for the last 23 layers of the model ==> Retain the features from the original MobileNet model\n",
    "for layer in model.layers[:-23]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Early stopping\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(x=train_batches,\n",
    "          steps_per_epoch=len(train_batches),\n",
    "          validation_data=valid_batches,\n",
    "          validation_steps=len(valid_batches),\n",
    "          epochs=20,\n",
    "          verbose=2,\n",
    "          callbacks=[early_stopping]\n",
    ")\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model\n",
    "\n",
    "model.save(\"/gdrive/MyDrive//Lab1_DPL302m/modelsaving\")\n",
    "#history = model.load_weights('/gdrive/MyDrive//Lab1_DPL302m/modelsaving')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating\n",
    "from sklearn.metrics import confusion_matrix, precision_score, f1_score as sklearn_f1_score, accuracy_score\n",
    "\n",
    "test_labels = test_batches.classes\n",
    "predictions = model.predict(x=test_batches, steps=len(test_batches), verbose=0)\n",
    "cm = confusion_matrix(y_true=test_labels, y_pred=predictions.argmax(axis=1))\n",
    "precision = precision_score(y_true=test_labels, y_pred=predictions.argmax(axis=1))\n",
    "f1_score = sklearn_f1_score(y_true=test_labels, y_pred=predictions.argmax(axis=1))\n",
    "accuracy = accuracy_score(y_true=test_labels, y_pred=predictions.argmax(axis=1))\n",
    "\n",
    "# Print precision, F1 score and accuracy of our model\n",
    "print('Precision: ', precision)\n",
    "print('F1 Score: ', f1_score)\n",
    "print('Accuracy: ', accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Draw plot Training và Validation Accuracy\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Draw plot Training và Validation Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Write predicted values ​​to CSV file\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "\n",
    "labels = ['1', '0']\n",
    "\n",
    "def preprocess_image(file_path):\n",
    "    img = image.load_img(file_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array_expanded_dims = np.expand_dims(img_array, axis=0)\n",
    "    return tf.keras.applications.mobilenet.preprocess_input(img_array_expanded_dims)\n",
    "\n",
    "def predict_image(file_path):\n",
    "    preprocessed_image = preprocess_image(file_path)\n",
    "    predictions = model.predict(preprocessed_image)\n",
    "    result = np.argmax(predictions)\n",
    "    return labels[result]\n",
    "\n",
    "\n",
    "dataset_dir = '.../Data/Dataset/testset'\n",
    "\n",
    "output_csv = '.../Data/Dataset/Predict_test.csv'\n",
    "\n",
    "predictions_list = []\n",
    "\n",
    "\n",
    "for filename in os.listdir(dataset_dir):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        file_path = os.path.join(dataset_dir, filename)\n",
    "        prediction = predict_image(file_path)\n",
    "        filename_without_extension = os.path.splitext(filename)[0]\n",
    "        predictions_list.append((filename_without_extension, prediction))\n",
    "\n",
    "\n",
    "with open(output_csv, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Filename', 'Prediction'])\n",
    "    for prediction in predictions_list:\n",
    "        writer.writerow(prediction)\n",
    "\n",
    "print(\"Predictions saved to\", output_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
